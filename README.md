# Karpathy-makemore
This repository is my implementation for `Andrej Karpathy's` [makemore](https://github.com/karpathy/makemore/blob/master/makemore.py)

[makemore_origin.py](https://github.com/Zhaohr1990/Karpathy-makemore/blob/main/makemore_origin.py) is my implementation following the original code, where Bigram, Ngram, MLP, Decoder models are incorporated. [illustration_notebook.ipynb](https://github.com/Zhaohr1990/Karpathy-makemore/blob/main/illustration_notebook.ipynb) is the illustrative notebook using models in [makemore_origin.py](https://github.com/Zhaohr1990/Karpathy-makemore/blob/main/makemore_origin.py). 

[makemore_hz.py](https://github.com/Zhaohr1990/Karpathy-makemore/blob/main/makemore_hz.py) is an updated implementation, where the dataset and dataloader are revised ([illustration_notebook_hz.ipynb](https://github.com/Zhaohr1990/Karpathy-makemore/blob/main/illustration_notebook_hz.ipynb) is the illustrative notebook). Instead of organizing the tensor at the word level, i.e., batch_size, max_word_length, feature_dimension, I construct the dataset based on markov_order/block_size, i.e., batch_size, markov_order, feature_dimension. This is more similar to the standard training of LLM, where block_size = max context window. The model objects are updated accordingly.
